{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae1786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_text(\n",
    "    text: str,\n",
    "    to_lower: bool = False,\n",
    "    min_tokens: int = 5,\n",
    "    noise_thresh: float = 0.5,\n",
    "    mask_numbers: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Perform comprehensive text cleaning to make data tokenizer-friendly:\n",
    "      1. Unicode normalization\n",
    "      2. Strip HTML tags and wiki-style markup\n",
    "      3. Normalize quotes/dashes\n",
    "      4. Remove control chars & collapse whitespace\n",
    "      5. Surround punctuation with spaces\n",
    "      6. Remove very short / noisy lines\n",
    "      7. Mask numbers\n",
    "      8. Deduplicate sentences\n",
    "    \"\"\"\n",
    "    # 1. Unicode normalize\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    \n",
    "    # 2. Strip HTML tags\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    #    Strip wiki headings and templates\n",
    "    text = re.sub(r\"^==+.*==+$\", \" \", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"\\{\\{.*?\\}\\}\", \" \", text, flags=re.DOTALL)\n",
    "    \n",
    "    # 3. Normalize quotes and dashes\n",
    "    text = text.replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    text = text.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    text = re.sub(r\"[–—]\", \"-\", text)\n",
    "    \n",
    "    # 4. Remove newlines/tabs and collapse whitespace\n",
    "    text = re.sub(r\"[\\r\\n\\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    if to_lower:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # 5. Surround punctuation so it's tokenized separately\n",
    "    text = re.sub(r'([.,!?;:\\(\\)\\[\\]\"\\-])', r' \\1 ', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # 6. Remove very short or noisy lines\n",
    "    lines = text.split(\". \")\n",
    "    clean_lines = []\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        if len(tokens) < min_tokens:\n",
    "            continue\n",
    "        non_word = sum(1 for c in line if not (c.isalnum() or c.isspace()))\n",
    "        if non_word / max(1, len(line)) > noise_thresh:\n",
    "            continue\n",
    "        clean_lines.append(line)\n",
    "    text = \". \".join(clean_lines)\n",
    "    \n",
    "    # 7. Mask all standalone numbers\n",
    "    if mask_numbers:\n",
    "        text = re.sub(r\"\\b\\d+(\\.\\d+)?\\b\", \"<NUM>\", text)\n",
    "    \n",
    "    # 8. Deduplicate sentences\n",
    "    sents = re.split(r'(?<=[\\.\\!\\?])\\s+', text)\n",
    "    seen, uniq = set(), []\n",
    "    for s in sents:\n",
    "        if s and s not in seen:\n",
    "            seen.add(s)\n",
    "            uniq.append(s)\n",
    "    text = \" \".join(uniq)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def load_and_preprocess(\n",
    "    dataset_name: str = \"wikitext\",\n",
    "    dataset_config: str = \"wikitext-103-raw-v1\",\n",
    "    splits: tuple[str, ...] = (\"train\", \"validation\", \"test\")\n",
    ") -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Load the given HF dataset splits, apply preprocessing, and return a DatasetDict.\n",
    "    \"\"\"\n",
    "    # Load all splits into a DatasetDict\n",
    "    ds_dict = load_dataset(dataset_name, dataset_config)\n",
    "    \n",
    "    # Apply preprocessing to each split\n",
    "    for split in splits:\n",
    "        ds = ds_dict[split]\n",
    "        ds = ds.map(\n",
    "            lambda ex: {\"text\": preprocess_text(ex[\"text\"], to_lower=False, mask_numbers=False)},\n",
    "            remove_columns=[c for c in ds.column_names if c != \"text\"],\n",
    "            batched=False,  # one example at a time\n",
    "        )\n",
    "        ds_dict[split] = ds\n",
    "    return ds_dict\n",
    "\n",
    "def save_to_df(ds: DatasetDict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the DatasetDict to a DataFrame for easy inspection.\n",
    "    \"\"\"\n",
    "    section = None\n",
    "    records = []\n",
    "    heading_re = re.compile(r'^[= ]+(.+?)[= ]+$')\n",
    "\n",
    "    for row in ds:\n",
    "        if row:\n",
    "            line = row.strip()\n",
    "            m = heading_re.match(line)\n",
    "            if m:\n",
    "                section = m.group(1)\n",
    "            else:\n",
    "                records.append((section, row))\n",
    "            \n",
    "    return pd.DataFrame(records, columns=[\"Section\",\"Text\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load & preprocess\n",
    "    processed = load_and_preprocess()\n",
    "    \n",
    "    # Save to disk for fast reload later\n",
    "    # processed.save_to_disk(\"data/processed_wikitext103\")\n",
    "    \n",
    "    # Save to DF for easy inspection\n",
    "    dataset_train = save_to_df(processed[\"train\"]['text'])\n",
    "    dataset_valid = save_to_df(processed[\"validation\"]['text'])\n",
    "    dataset_test = save_to_df(processed[\"test\"]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edb2827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1801350\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a14b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '= Valkyria Chronicles III =',\n",
       " '',\n",
       " 'Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @ - @ playing video game developed by Sega and Media . Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @ - @ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" .',\n",
       " \"The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n .\",\n",
       " \"It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 .\",\n",
       " '',\n",
       " '= = Gameplay = =',\n",
       " '',\n",
       " \"As with previous Valkyira Chronicles games , Valkyria Chronicles III is a tactical role @ - @ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @ - @ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @ - @ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main heroines , although they take a very minor role .\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['train']['text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36dac95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valkyria Chronicles III</td>\n",
       "      <td>Senjō no Valkyria 3 : Unrecorded Chronicles ( ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valkyria Chronicles III</td>\n",
       "      <td>The game began development in 2010 , carrying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valkyria Chronicles III</td>\n",
       "      <td>It met with positive sales in Japan , and was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gameplay</td>\n",
       "      <td>As with previous Valkyira Chronicles games , V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gameplay</td>\n",
       "      <td>The game 's battle system , the BliTZ system ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gameplay</td>\n",
       "      <td>Troops are divided into five classes : Scouts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plot</td>\n",
       "      <td>The game takes place during the Second Europan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plot</td>\n",
       "      <td>As the Nameless officially do not exist , the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plot</td>\n",
       "      <td>Partly due to these events , and partly due to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Development</td>\n",
       "      <td>Concept work for Valkyria Chronicles III began...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Section                                               Text\n",
       "0  Valkyria Chronicles III  Senjō no Valkyria 3 : Unrecorded Chronicles ( ...\n",
       "1  Valkyria Chronicles III  The game began development in 2010 , carrying ...\n",
       "2  Valkyria Chronicles III  It met with positive sales in Japan , and was ...\n",
       "3                 Gameplay  As with previous Valkyira Chronicles games , V...\n",
       "4                 Gameplay  The game 's battle system , the BliTZ system ,...\n",
       "5                 Gameplay  Troops are divided into five classes : Scouts ...\n",
       "6                     Plot  The game takes place during the Second Europan...\n",
       "7                     Plot  As the Nameless officially do not exist , the ...\n",
       "8                     Plot  Partly due to these events , and partly due to...\n",
       "9              Development  Concept work for Valkyria Chronicles III began..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2c4e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>832788</td>\n",
       "      <td>832788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>111725</td>\n",
       "      <td>817953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>History</td>\n",
       "      <td>Note : Flags indicate national team as defined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14511</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Section                                               Text\n",
       "count    832788                                             832788\n",
       "unique   111725                                             817953\n",
       "top     History  Note : Flags indicate national team as defined...\n",
       "freq      14511                                                 92"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc52b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 832788 text samples to output_train.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832788/832788 [00:01<00:00, 683921.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output_train.txt\n",
      "\n",
      "Preview of saved data:\n",
      "Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @ - @ playing video game developed by Sega and Media . Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @ - @ time gameplay as its predecessors , the story runs parallel to the first game  ...\n",
      "Saving 1795 text samples to output_valid.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1795/1795 [00:00<00:00, 565011.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output_valid.txt\n",
      "\n",
      "Preview of saved data:\n",
      "Homarus gammarus , known as the European lobster or common lobster , is a species of clawed lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save only the Text column to a single file for training\n",
    "output_train_file = \"output_train.txt\"\n",
    "print(f\"Saving {len(dataset_train)} text samples to {output_train_file}...\")\n",
    "\n",
    "# Save the text content to a single file\n",
    "with open(output_train_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in tqdm(dataset_train[\"Text\"]):\n",
    "        if text and isinstance(text, str) and len(text.strip()) > 0:\n",
    "            f.write(text.strip() + \"\\n\\n\")\n",
    "\n",
    "print(f\"Data saved to {output_train_file}\")\n",
    "\n",
    "# Check the first few lines of the saved file\n",
    "with open(output_train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    preview = f.read(1000)\n",
    "print(\"\\nPreview of saved data:\")\n",
    "print(preview[:500], \"...\")\n",
    "\n",
    "\n",
    "\n",
    "output_valid_file = \"output_valid.txt\"\n",
    "print(f\"Saving {len(dataset_valid)} text samples to {output_valid_file}...\")\n",
    "with open(output_valid_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in tqdm(dataset_valid[\"Text\"]):\n",
    "        if text and isinstance(text, str) and len(text.strip()) > 0:\n",
    "            f.write(text.strip() + \"\\n\\n\")\n",
    "\n",
    "print(f\"Data saved to {output_valid_file}\")\n",
    "\n",
    "# Check the first few lines of the saved file\n",
    "with open(output_valid_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    preview = f.read(1000)\n",
    "print(\"\\nPreview of saved data:\")\n",
    "print(preview[:500], \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
